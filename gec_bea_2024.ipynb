{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**This notebook shows an encoder-decoder model for Grammatical Error Correction. The following notebook was based on [Ben Trevettâ€™s seq2seq tutorial](https://github.com/bentrevett/pytorch-seq2seq/). The main modification is to adapt the model from machine translation to grammatical error correction.**"
      ],
      "metadata": {
        "id": "qTr4d0JAyOzJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj9g6wuSG8ST"
      },
      "source": [
        "Change current working directory to Google drive to access necessary files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hT0df-L7JFb",
        "outputId": "e92cf6a7-81ee-4e0f-e293-f1fcd6af51e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_HnmdkAuz-k"
      },
      "source": [
        "#Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EqfQqVtFRRI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "PATH = r\"/content/gdrive/My Drive/Colab Notebooks/gec_bea_2024\"\n",
        "os.chdir(PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZGFdCitGkLm"
      },
      "source": [
        "## Customized preprocessor\n",
        "\n",
        "m2_data_preprocessor.py contains a customized class to preprocess m2 files from the BEA 2019 challenge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wG55NwkvFY1h"
      },
      "outputs": [],
      "source": [
        "from m2_data_preprocessor import DataPreprocessor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ra9Qdn7PHFeV"
      },
      "source": [
        "Installing and importing necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eroA9iQKGWU2"
      },
      "outputs": [],
      "source": [
        "# !pip install torchtext==0.17.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A63EfPs_GWSB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5bc96f7-0aa5-412d-fcb6-b6c63ba9aaf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/utils.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchtext.vocab\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gutiatsmGWIH",
        "outputId": "e0443be3-4b74-4e31-eb75-51220777afc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3.0+cu121\n",
            "0.18.0+cpu\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__)\n",
        "print(torchtext.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6VE6oQyGixP",
        "outputId": "d1a87f09-abb6-49f6-de41-eef26f17276b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "available_gpu = torch.cuda.is_available()\n",
        "if available_gpu:\n",
        "  print(f\"GPU is available: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "  print(\"GPU not available.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BM8hCPWhSQKB"
      },
      "source": [
        "Setting seeds for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVHMzAyuSPoa"
      },
      "outputs": [],
      "source": [
        "seed = 42\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reverse = False  # If True, source tokens are used in reverse for training: Consider (Sutskever et al. 2014)"
      ],
      "metadata": {
        "id": "JkkESVEmMa-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMbMcqbCHyQN"
      },
      "source": [
        "#Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2SwwH93HK_9"
      },
      "source": [
        "Setting paths for data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmLmHK-KFlQE"
      },
      "outputs": [],
      "source": [
        "# File names from BEA 2019\n",
        "\n",
        "A_train = \"A.train.gold.bea19.m2\"\n",
        "B_train = \"B.train.gold.bea19.m2\"\n",
        "C_train = \"C.train.gold.bea19.m2\"\n",
        "\n",
        "A_dev = \"A.dev.gold.bea19.m2\"\n",
        "B_dev = \"B.dev.gold.bea19.m2\"\n",
        "C_dev = \"C.dev.gold.bea19.m2\"\n",
        "\n",
        "training_raw_data = [A_train, B_train, C_train]\n",
        "validation_raw_data = [A_dev, B_dev, C_dev]\n",
        "\n",
        "N_test = \"N.dev.gold.bea19.m2\"\n",
        "\n",
        "# Path to data of current project\n",
        "\n",
        "hard_path = \"data/m2/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94KuR-fOHVVK"
      },
      "source": [
        "Preprocessing training data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvFiB8zsFzlw",
        "outputId": "ee772d0d-7b3e-4668-bb8f-5fdff664d1db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68326\n",
            "[{'src': 'Finally , I will have high salary when I am Journalist .', 'tgt': 'Finally , I will have a high salary when I am a journalist .'}, {'src': \"To be Journalist , I must study very hard so I 'll try to learn in order to make my dream comes true .\", 'tgt': \"To be a journalist , I must study very hard , so I 'll try to learn in order to make my dream come true .\"}, {'src': \"In the future , I 'll become a journalist .\", 'tgt': \"In the future , I 'll become a journalist .\"}, {'src': 'Now days each family has more then 1 car for each one , this is only one of few reason that people use less public transport .', 'tgt': 'Nowadays , each family has more than 1 car for each person , this is only one of several reasons why people use less public transport .'}, {'src': 'Before was really convenient to go by bus or by train but with the new economy the travel tickets are more expensive and a big difference from the past is that it is less expensive to go far then near .', 'tgt': 'Before , it was really convenient to go by bus or by train , but with the new economy , the fares are more expensive and a big difference from the past is that it is less expensive to go long - distance than short journeys .'}]\n"
          ]
        }
      ],
      "source": [
        "preprocessor_training = DataPreprocessor()\n",
        "\n",
        "for file in training_raw_data:\n",
        "  preprocessor_training.read_m2_data(hard_path + file)\n",
        "\n",
        "print(len(preprocessor_training.data))\n",
        "print(preprocessor_training.data[15:20])\n",
        "\n",
        "train_data = preprocessor_training.data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enlarge training data with more examples of correct sentences."
      ],
      "metadata": {
        "id": "1Am2J9y6s09Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_only_correct = []\n",
        "\n",
        "for element in train_data:\n",
        "  element[\"tgt\"]\n",
        "\n",
        "  train_data_only_correct.append({\"src\": element[\"tgt\"], \"tgt\": element[\"tgt\"]})\n",
        "\n",
        "print(len(train_data_only_correct))\n",
        "print(train_data_only_correct[15:20])\n",
        "\n",
        "train_data = train_data + train_data_only_correct\n",
        "\n",
        "print(len(train_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hw2q9FFvsz4-",
        "outputId": "e9e14853-9f9d-4794-daeb-f3ed7f251a8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68326\n",
            "[{'src': 'Finally , I will have a high salary when I am a journalist .', 'tgt': 'Finally , I will have a high salary when I am a journalist .'}, {'src': \"To be a journalist , I must study very hard , so I 'll try to learn in order to make my dream come true .\", 'tgt': \"To be a journalist , I must study very hard , so I 'll try to learn in order to make my dream come true .\"}, {'src': \"In the future , I 'll become a journalist .\", 'tgt': \"In the future , I 'll become a journalist .\"}, {'src': 'Nowadays , each family has more than 1 car for each person , this is only one of several reasons why people use less public transport .', 'tgt': 'Nowadays , each family has more than 1 car for each person , this is only one of several reasons why people use less public transport .'}, {'src': 'Before , it was really convenient to go by bus or by train , but with the new economy , the fares are more expensive and a big difference from the past is that it is less expensive to go long - distance than short journeys .', 'tgt': 'Before , it was really convenient to go by bus or by train , but with the new economy , the fares are more expensive and a big difference from the past is that it is less expensive to go long - distance than short journeys .'}]\n",
            "136652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jc4DXqkuHbwW"
      },
      "source": [
        "Preprocessing validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ntr6Q8eMF9Ke",
        "outputId": "0b429f3e-8d73-482c-d0b8-8455d81bebb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6760\n",
            "[{'src': 'I think that the public transport will always be in the future .', 'tgt': 'I think that public transport will always exist in the future .'}, {'src': 'The rich people will buy a car but the poor people always need to use a bus or taxi .', 'tgt': 'Rich people will buy a car , but poor people always need to use a bus or taxi .'}, {'src': 'I consider that is more convenient to drive a car because you carry on more things in your own car than travelling by car .', 'tgt': 'I consider it more convenient to drive a car , because you carry more things in your own car than when travelling by car .'}, {'src': \"Also , you 'll meet friendly people who usually ask to you something to be friends and change your telephone number .\", 'tgt': \"Also , you 'll meet friendly people who usually ask you to be friends and exchange telephone numbers .\"}, {'src': \"In my experience when I did n't have a car I used to use the bus to go to the school and go back to my house .\", 'tgt': \"In my experience , when I did n't have a car I used to use the bus to go to school and go back to my house .\"}]\n"
          ]
        }
      ],
      "source": [
        "preprocessor_val = DataPreprocessor()\n",
        "\n",
        "for file in validation_raw_data:\n",
        "  preprocessor_val.read_m2_data(hard_path + file)\n",
        "\n",
        "print(len(preprocessor_val.data))\n",
        "print(preprocessor_val.data[5:10])\n",
        "\n",
        "val_data = preprocessor_val.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Eyg64zSK7NE"
      },
      "source": [
        "Preparing test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbvAfyEAK6j5",
        "outputId": "9fef27ef-d748-4e23-aa1e-e2aa7c20b47f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "988\n",
            "[{'src': 'Boxing is a common , well known and well loved sport amongst most countries in the world however it is also punishing , dangerous and disliked to the extent that many people want it banned , possibly with good reason .', 'tgt': 'Boxing is a common , well - known and well - loved sport in most countries in the world . However , it is also punishing , dangerous and disliked to the extent that many people want it banned , possibly with good reason .'}, {'src': 'Boxing is a dangerous sport , there are relatively common deaths , tragic injuries and even disease .', 'tgt': 'Boxing is a dangerous sport . There are relatively common deaths , tragic injuries and even disease .'}, {'src': 'All professional boxers are at risk from being killed in his next fight .', 'tgt': 'All professional boxers are at risk from being killed in their next fight .'}, {'src': 'If not killed then more likely paralysed .', 'tgt': 'If not killed , then more likely paralysed .'}, {'src': 'There have been a number of cases in the last ten years of the top few boxers having tragic losses throughout their ranks .', 'tgt': 'There have been a number of cases in the last ten years of the top few boxers having tragic losses among their ranks .'}]\n"
          ]
        }
      ],
      "source": [
        "preprocessor_test = DataPreprocessor()\n",
        "\n",
        "preprocessor_test.read_m2_data(hard_path + N_test)\n",
        "\n",
        "print(len(preprocessor_test.data))\n",
        "print(preprocessor_test.data[0:5])\n",
        "\n",
        "test_data = preprocessor_test.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi81SiwULg1I"
      },
      "source": [
        "Trimming sentences and adding sos and eos tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z53np90MKdKc"
      },
      "outputs": [],
      "source": [
        "def trim_sentences(input_dict, max_length, lower, reverse, sos_token, eos_token):\n",
        "\n",
        "    src_tokens = [entry for entry in input_dict[\"src\"].split()][:max_length]\n",
        "    tgt_tokens = [entry for entry in input_dict[\"tgt\"].split()][:max_length]\n",
        "\n",
        "    if lower:\n",
        "        src_tokens = [token.lower() for token in src_tokens]\n",
        "        tgt_tokens = [token.lower() for token in tgt_tokens]\n",
        "\n",
        "    if reverse:  # Reversing source sentence\n",
        "      src_tokens = src_tokens[::-1]\n",
        "\n",
        "    src_tokens = [sos_token] + src_tokens + [eos_token]\n",
        "    tgt_tokens = [sos_token] + tgt_tokens + [eos_token]\n",
        "\n",
        "    input_dict[\"src_tokens\"] = src_tokens\n",
        "    input_dict[\"tgt_tokens\"] = tgt_tokens\n",
        "\n",
        "    return input_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itIJbInmKf-o"
      },
      "outputs": [],
      "source": [
        "max_length = 25\n",
        "lower = True\n",
        "sos_token = \"<sos>\"\n",
        "eos_token = \"<eos>\"\n",
        "\n",
        "train_data = list(map(lambda x: trim_sentences(x, max_length, lower, reverse, sos_token,\n",
        "                                               eos_token), train_data))\n",
        "\n",
        "val_data = list(map(lambda x: trim_sentences(x, max_length, lower, reverse, sos_token,\n",
        "                                             eos_token), val_data))\n",
        "\n",
        "test_data = list(map(lambda x: trim_sentences(x, max_length, lower, reverse, sos_token,\n",
        "                                              eos_token), test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiycGVTpVkrP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f3ad1a3-9b8a-4329-9e5c-84d23ad2bd7b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'src': 'Do you know mountain biking ?',\n",
              " 'tgt': 'Do you know about mountain biking ?',\n",
              " 'src_tokens': ['<sos>',\n",
              "  'do',\n",
              "  'you',\n",
              "  'know',\n",
              "  'mountain',\n",
              "  'biking',\n",
              "  '?',\n",
              "  '<eos>'],\n",
              " 'tgt_tokens': ['<sos>',\n",
              "  'do',\n",
              "  'you',\n",
              "  'know',\n",
              "  'about',\n",
              "  'mountain',\n",
              "  'biking',\n",
              "  '?',\n",
              "  '<eos>']}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "train_data[30]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t26l55zUo19r"
      },
      "source": [
        "# Vocabularies\n",
        "\n",
        "Each word will receive a number within the given vocabulary. Unknown words receive \"unk\" and are labeled with index 0.\n",
        "\n",
        "The vocabulary is enriched with special tokens: *unk_token*, *sos_token*, *eos_token*, and *\\<pad\\>*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3IaglFco1r8"
      },
      "outputs": [],
      "source": [
        "# Merging entries from training data to build rich vodabulary\n",
        "train_data_src_list = [entry['src_tokens'] for entry in train_data]\n",
        "train_data_tgt_list = [entry['tgt_tokens'] for entry in train_data]\n",
        "train_data_list = train_data_src_list + train_data_tgt_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12YpejVOrJ_U"
      },
      "outputs": [],
      "source": [
        "min_freq = 3\n",
        "unk_token = \"<unk>\"\n",
        "pad_token = \"<pad>\"\n",
        "\n",
        "special_tokens = [\n",
        "  unk_token,\n",
        "  pad_token,\n",
        "  sos_token,\n",
        "  eos_token,\n",
        "]\n",
        "\n",
        "# Torch is building the vocabulary with indeces\n",
        "en_vocab = torchtext.vocab.build_vocab_from_iterator(\n",
        "  train_data_list,\n",
        "  min_freq=min_freq,\n",
        "  specials=special_tokens,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLWQl6nMr52F"
      },
      "source": [
        "Testing vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EC5nkvuisPp4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bf115f0-06ca-4243-8d30-b584c25d40f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', '<pad>', '<sos>', '<eos>', '.', ',', 'the', 'to', 'and', 'i']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "en_vocab.get_itos()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKhTQd9jsPf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f558f5ab-2b21-4ee0-d083-c015f145e881"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "en_vocab.get_itos()[9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4STQ7jWsPcW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e271f33-6015-4e9c-f1cb-33e2244fe0d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "en_vocab.get_stoi()[\"the\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPMsq-yysTF7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7cccc82-150b-4d1a-bce9-9373e4c33a57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "en_vocab[\"the\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jl1kb-zVsUsA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9002f05-9f07-4cb2-db0a-fb835c67d9bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18925"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "len(en_vocab) # With larger training data, e.g. by adding correct examples, the vocab increases -> because min_freq is now met more often"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CD7APEkJsntf"
      },
      "source": [
        "Torch text does not automatically assign a value to *unk* and other specific tokens. Therefore, if a word is unknown so far no numerical value is returned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DERk-RN2s6SV"
      },
      "outputs": [],
      "source": [
        "unk_index = en_vocab[unk_token]\n",
        "pad_index = en_vocab[pad_token]\n",
        "en_vocab.set_default_index(unk_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEovaMjhs64W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "282fc503-8ac6-4ed7-e575-3d36941dd444"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "\"The\" in en_vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8C1G8XKfs-x0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec24ad29-e97f-4b1c-ca1e-97298f447ca7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "en_vocab[\"The\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liDoCkEitT5J"
      },
      "source": [
        "Testing indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2qTOXc6tU_t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "605e2e86-6ebe-4f3c-bbfe-0959bf0c95c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9, 129, 401, 2324, 586]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "tokens = [\"i\", \"love\", \"watching\", \"crime\", \"shows\"]\n",
        "en_vocab.lookup_indices(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4RyXbvVt2YJ"
      },
      "outputs": [],
      "source": [
        "def numericalize_example(input_dict, en_vocab):\n",
        "\n",
        "  src_ids = en_vocab.lookup_indices(input_dict[\"src_tokens\"])\n",
        "  tgt_ids = en_vocab.lookup_indices(input_dict[\"tgt_tokens\"])\n",
        "\n",
        "  # Token ids are saved as torch tensors: See type(train_data[0][\"src_ids\"])\n",
        "  input_dict[\"src_ids\"] = torch.tensor(src_ids, dtype=torch.int64)\n",
        "  input_dict[\"tgt_ids\"] = torch.tensor(tgt_ids, dtype=torch.int64)\n",
        "\n",
        "  return input_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWEoZCmQuHiD"
      },
      "outputs": [],
      "source": [
        "train_data = list(map(lambda x: numericalize_example(x, en_vocab), train_data))\n",
        "val_data = list(map(lambda x: numericalize_example(x, en_vocab), val_data))\n",
        "test_data = list(map(lambda x: numericalize_example(x, en_vocab), test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PD4bGPfUuIV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bcc87fe-e957-4e07-dee3-9eb23c514908"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'src': 'My town is a medium size city with eighty thousand inhabitants .',\n",
              " 'tgt': 'My town is a medium - sized city with eighty thousand inhabitants .',\n",
              " 'src_tokens': ['<sos>',\n",
              "  'my',\n",
              "  'town',\n",
              "  'is',\n",
              "  'a',\n",
              "  'medium',\n",
              "  'size',\n",
              "  'city',\n",
              "  'with',\n",
              "  'eighty',\n",
              "  'thousand',\n",
              "  'inhabitants',\n",
              "  '.',\n",
              "  '<eos>'],\n",
              " 'tgt_tokens': ['<sos>',\n",
              "  'my',\n",
              "  'town',\n",
              "  'is',\n",
              "  'a',\n",
              "  'medium',\n",
              "  '-',\n",
              "  'sized',\n",
              "  'city',\n",
              "  'with',\n",
              "  'eighty',\n",
              "  'thousand',\n",
              "  'inhabitants',\n",
              "  '.',\n",
              "  '<eos>'],\n",
              " 'src_ids': tensor([   2,   18,  185,   13,   10, 3108, 1602,  107,   23, 9432, 2150, 2490,\n",
              "            4,    3]),\n",
              " 'tgt_ids': tensor([   2,   18,  185,   13,   10, 3108,   67, 6965,  107,   23, 9432, 2150,\n",
              "         2490,    4,    3])}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "train_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xH7_K8rIujaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20c76911-0549-465e-c6fa-48801d646682"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "type(train_data[0][\"src_ids\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KsY95Qjuqu6"
      },
      "source": [
        "#Data Loader\n",
        "\n",
        "Data loader helps to combine the training instances into batches. For successful batches, padding is needed so that each batch has equal size.\n",
        "\n",
        "\"The `get_collate_fn` takes in the padding token index and returns the `collate_fn` defined inside it. This technique, of defining a function inside another and returning it, is known as a [closure](<https://en.wikipedia.org/wiki/Closure_(computer_programming)>). It allows the `collate_fn` to continually use the value of `pad_index` it was created with without creating a class or using global variables.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NokyrClOuroL"
      },
      "outputs": [],
      "source": [
        "def get_collate_fn(pad_index):\n",
        "\n",
        "  def collate_fn(batch):\n",
        "\n",
        "    batch_src_ids = [example[\"src_ids\"] for example in batch]\n",
        "    batch_tgt_ids = [example[\"tgt_ids\"] for example in batch]\n",
        "    batch_src_ids = nn.utils.rnn.pad_sequence(batch_src_ids, padding_value=pad_index)\n",
        "    batch_tgt_ids = nn.utils.rnn.pad_sequence(batch_tgt_ids, padding_value=pad_index)\n",
        "\n",
        "    batch = {\n",
        "      \"src_ids\": batch_src_ids,\n",
        "      \"tgt_ids\": batch_tgt_ids,\n",
        "    }\n",
        "\n",
        "    return batch\n",
        "\n",
        "  return collate_fn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7BMJGeqwEJR"
      },
      "source": [
        "Question: What happens when batches are being shuffled here? -- they are shuffled for training, but not for the validation and test sets.\n",
        "\n",
        "Shuffling the training data can improve the stability of the training process and potentially enhance the model's overall performance. However, this step is only required for the training set. The metrics for the validation and test sets will remain consistent, regardless of the data order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOMyZvrwv6BG"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
        "\n",
        "  collate_fn = get_collate_fn(pad_index)\n",
        "\n",
        "  data_loader = torch.utils.data.DataLoader(\n",
        "    dataset=dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=collate_fn,\n",
        "    shuffle=shuffle,\n",
        "  ) # Try \"pin_memory = True\" / \"num_workers = 2\"\n",
        "\n",
        "  return data_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TR34uGnZwi4e"
      },
      "source": [
        "Batch size should correspond to memory of GPU.\n",
        "\n",
        "Question: How to find out about the current memory?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9esBjrgkwRr8"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "\n",
        "train_data_loader = get_data_loader(train_data, batch_size, pad_index, shuffle=True)\n",
        "val_data_loader = get_data_loader(val_data, batch_size, pad_index)\n",
        "test_data_loader = get_data_loader(test_data, batch_size, pad_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xfFiIcTww8t"
      },
      "source": [
        "#The model\n",
        "\n",
        "The model has three parts: Encoder, Decoder, and seq2seq. All shall be implemented separately."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFD52fsT68F9"
      },
      "source": [
        "##1) Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHI6TO-kwzgQ"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
        "\n",
        "    super().__init__() # Inherit boilerplate code from Torch\n",
        "\n",
        "    self.hidden_dim = hidden_dim  # Dimension of one-hot vectors\n",
        "    self.n_layers = n_layers  # Number of layers in LSTM network\n",
        "    self.embedding = nn.Embedding(input_dim, embedding_dim)  # Converts one-hot vectors into lower dimension embeddings\n",
        "    self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout)\n",
        "    self.dropout = nn.Dropout(dropout)  # Regularization parameter\n",
        "\n",
        "  def forward(self, src):  # src = [src length, batch size]\n",
        "\n",
        "    embedded = self.dropout(self.embedding(src)) # embedded = [src length, batch size, embedding dim]\n",
        "\n",
        "    outputs, (hidden, cell) = self.rnn(embedded)\n",
        "    # outputs = [src length, batch size, hidden dim * n directions]\n",
        "    # hidden = [n layers * n directions, batch size, hidden dim]\n",
        "    # cell = [n layers * n directions, batch size, hidden dim]\n",
        "    # outputs are always from the top hidden layer\n",
        "\n",
        "    return hidden, cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meOvRpWd69wN"
      },
      "source": [
        "##2) Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBF0wops6-9z"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, output_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    self.output_dim = output_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.n_layers = n_layers\n",
        "    self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
        "    self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout)\n",
        "    self.fc_out = nn.Linear(hidden_dim, output_dim)  # Additional output layer for predictions\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, input, hidden, cell):\n",
        "    # input = [batch size]\n",
        "    # hidden = [n layers * n directions, batch size, hidden dim]\n",
        "    # cell = [n layers * n directions, batch size, hidden dim]\n",
        "    # n directions in the decoder will both always be 1, therefore:\n",
        "    # hidden = [n layers, batch size, hidden dim]\n",
        "    # context = [n layers, batch size, hidden dim]\n",
        "\n",
        "    input = input.unsqueeze(0)  # input = [1, batch size]\n",
        "\n",
        "    embedded = self.dropout(self.embedding(input))  # embedded = [1, batch size, embedding dim]\n",
        "\n",
        "    output, (hidden, cell) = self.rnn(embedded, (hidden, cell))  # output = [seq length, batch size, hidden dim * n directions]\n",
        "\n",
        "    # hidden = [n layers * n directions, batch size, hidden dim]\n",
        "    # cell = [n layers * n directions, batch size, hidden dim]\n",
        "    # seq length and n directions will always be 1 in this decoder, therefore:\n",
        "    # output = [1, batch size, hidden dim]\n",
        "    # hidden = [n layers, batch size, hidden dim]\n",
        "    # cell = [n layers, batch size, hidden dim]\n",
        "\n",
        "    prediction = self.fc_out(output.squeeze(0))  # prediction = [batch size, output dim]\n",
        "\n",
        "    return prediction, hidden, cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmI3PSbu8UDo"
      },
      "source": [
        "##3) seq2seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfzCBtz28V2N"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, encoder, decoder, device):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.device = device  # GPU if available\n",
        "\n",
        "    assert (\n",
        "      encoder.hidden_dim == decoder.hidden_dim\n",
        "    ), \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "\n",
        "    assert (\n",
        "      encoder.n_layers == decoder.n_layers\n",
        "    ), \"Encoder and decoder must have equal number of layers!\"\n",
        "\n",
        "  def forward(self, src, tgt, teacher_forcing_ratio):\n",
        "    # src = [src length, batch size]\n",
        "    # tgt = [tgt length, batch size]\n",
        "    # teacher_forcing_ratio is probability to use teacher forcing\n",
        "    # e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
        "\n",
        "    batch_size = tgt.shape[1]\n",
        "    tgt_length = tgt.shape[0]\n",
        "    tgt_vocab_size = self.decoder.output_dim\n",
        "\n",
        "    # tensor to store decoder outputs\n",
        "    outputs = torch.zeros(tgt_length, batch_size, tgt_vocab_size).to(self.device)\n",
        "\n",
        "    # last hidden state of the encoder is used as the initial hidden state of the decoder\n",
        "    hidden, cell = self.encoder(src) # hidden = [n layers * n directions, batch size, hidden dim]\n",
        "    # cell = [n layers * n directions, batch size, hidden dim]\n",
        "    # first input to the decoder is the <sos> tokens\n",
        "\n",
        "    input = tgt[0, :]  # input = [batch size]\n",
        "\n",
        "    for t in range(1, tgt_length):\n",
        "      # insert input token embedding, previous hidden and previous cell states\n",
        "      # receive output tensor (predictions) and new hidden and cell states\n",
        "\n",
        "      output, hidden, cell = self.decoder(input, hidden, cell)  # output = [batch size, output dim]\n",
        "      # hidden = [n layers, batch size, hidden dim]\n",
        "      # cell = [n layers, batch size, hidden dim]\n",
        "      # place predictions in a tensor holding predictions for each token\n",
        "\n",
        "      outputs[t] = output\n",
        "\n",
        "      # decide if we are going to use teacher forcing or not\n",
        "      teacher_force = random.random() < teacher_forcing_ratio\n",
        "\n",
        "      # get the highest predicted token from our predictions\n",
        "      top1 = output.argmax(1)\n",
        "\n",
        "      # if teacher forcing, use actual next token as next input\n",
        "      # if not, use predicted token\n",
        "      input = tgt[t] if teacher_force else top1  # input = [batch size]\n",
        "\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPxP8eXDCw2V"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwDcTo26C_ZB"
      },
      "source": [
        "## Instantiating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKguclCOCzNW"
      },
      "outputs": [],
      "source": [
        "input_dim = len(en_vocab)\n",
        "output_dim = len(en_vocab)\n",
        "\n",
        "encoder_embedding_dim = 256  # 256, 300, 1000\n",
        "decoder_embedding_dim = 256  # 256, 300, 1000\n",
        "\n",
        "hidden_dim = 512  # 512, 600, 2000 What does hidden dimensions? -- corresponds to the size of the hidden state of LSTM layer\n",
        "\n",
        "n_layers = 2  # 4?\n",
        "\n",
        "encoder_dropout = 0.5  # 0.25, 0.5, 0.75 It should be 0.5 (Raschka et al. 2022)\n",
        "decoder_dropout = 0.5\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "encoder = Encoder(\n",
        "  input_dim,\n",
        "  encoder_embedding_dim,\n",
        "  hidden_dim,\n",
        "  n_layers,\n",
        "  encoder_dropout,\n",
        ")\n",
        "\n",
        "decoder = Decoder(\n",
        "  output_dim,\n",
        "  decoder_embedding_dim,\n",
        "  hidden_dim,\n",
        "  n_layers,\n",
        "  decoder_dropout,\n",
        ")\n",
        "\n",
        "model = Seq2Seq(encoder, decoder, device).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-OO31SpDScW"
      },
      "source": [
        "## Weights\n",
        "\n",
        "\"In the paper they state they initialize all weights from a uniform distribution between -0.08 and +0.08, i.e. $\\mathcal{U}(-0.08, 0.08)$.\" (Trevett 2024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbXwP3ayDTsQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf0e217b-b9d5-48c4-8bd8-de412197e24c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(18925, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(18925, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (fc_out): Linear(in_features=512, out_features=18925, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "def init_weights(m):\n",
        "\n",
        "  for name, param in m.named_parameters():\n",
        "\n",
        "    # Samples are taken form a uniform distribution, this corresponds to values ranging between [-0.08, 0.08]\n",
        "    nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "\n",
        "\n",
        "model.apply(init_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1qitWaSE4gq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d72a787b-6071-4d22-9cbe-ad1dcc5360f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 26,754,541 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "print(f\"The model has {count_parameters(model):,} trainable parameters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MzoImgKE5Hc"
      },
      "source": [
        "##Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nd-bTRyqEzOG"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-8hPQhrHzZa"
      },
      "source": [
        "##Loss function\n",
        "\n",
        "\"Our loss function calculates the average loss per token, however by passing the index of the `<pad>` token as the `ignore_index` argument we ignore the loss whenever the target token is a padding token.\" (Trevett 2024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ORfA8d-H1we"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLmPeBB2IDSn"
      },
      "source": [
        "##Training loop\n",
        "\n",
        "\"At each iteration:\n",
        "\n",
        "-   get the source and target sentences from the batch, $X$ and $Y$\n",
        "-   zero the gradients calculated from the last batch\n",
        "-   feed the source and target into the model to get the output, $\\hat{Y}$\n",
        "-   as the loss function only works on 2d inputs with 1d targets we need to flatten each of them with `.view`\n",
        "    -   we slice off the first column of the output and target tensors as mentioned above\n",
        "-   calculate the gradients with `loss.backward()`\n",
        "-   clip the gradients to prevent them from exploding (a common issue in RNNs)\n",
        "-   update the parameters of our model by doing an optimizer step\n",
        "-   sum the loss value to a running total\" (Trevett 2024)\n",
        "\n",
        "Clipping might not be necessarily needed with the LSTM; but experiences appear to differ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTqDoeiSIFHj"
      },
      "outputs": [],
      "source": [
        "def train_fn(\n",
        "    model,\n",
        "    data_loader,\n",
        "    optimizer,\n",
        "    criterion,\n",
        "    clip,\n",
        "    teacher_forcing_ratio,\n",
        "    device\n",
        "):\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  epoch_loss = 0\n",
        "\n",
        "  for i, batch in enumerate(data_loader):\n",
        "\n",
        "    src = batch[\"src_ids\"].to(device)  # src = [src length, batch size]\n",
        "    tgt = batch[\"tgt_ids\"].to(device)  # tgt = [tgt length, batch size]\n",
        "\n",
        "\n",
        "    optimizer.zero_grad()  # Zero out gradients in the optimizer form previous step\n",
        "\n",
        "    output = model(src, tgt, teacher_forcing_ratio)  # output = [tgt length, batch size, tgt vocab size] as predictions\n",
        "\n",
        "    output_dim = output.shape[-1]\n",
        "\n",
        "    output = output[1:].view(-1, output_dim)  # output = [(tgt length - 1) * batch size, tgt vocab size]\n",
        "\n",
        "    tgt = tgt[1:].view(-1)  # tgt = [(tgt length - 1) * batch size]\n",
        "\n",
        "    loss = criterion(output, tgt)  # Calculate loss\n",
        "    loss.backward()  # Compute gradients\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)  # Clipping against exploding gradients\n",
        "\n",
        "    optimizer.step()  # Update parameters using gradients\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "  return epoch_loss / len(data_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkggAYzoLMMc"
      },
      "source": [
        "##Evaluation loop\n",
        "\n",
        "\"Our evaluation loop is similar to our training loop, however as we aren't updating any parameters we don't need to pass an optimizer or a clip value.\n",
        "\n",
        "We must remember to set the model to evaluation mode with `model.eval()`. This will turn off dropout (and batch normalization, if used).\n",
        "\n",
        "We use the `with torch.no_grad()` block to ensure no gradients are calculated within the block. This reduces memory consumption and speeds things up.\" (Trevett 2024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccXsjqc9LNtT"
      },
      "outputs": [],
      "source": [
        "def evaluate_fn(model, data_loader, criterion, device):\n",
        "\n",
        "  model.eval()\n",
        "  epoch_loss = 0\n",
        "\n",
        "  with torch.no_grad(): # Context-manager that disables gradient calculation: Helps with inferencing.\n",
        "\n",
        "    for i, batch in enumerate(data_loader):\n",
        "\n",
        "      src = batch[\"src_ids\"].to(device)  # src = [src length, batch size]\n",
        "      tgt = batch[\"tgt_ids\"].to(device)  # tgt = [tgt length, batch size]\n",
        "\n",
        "      output = model(src, tgt, 0)  # turn off teacher forcing\n",
        "      # output = [tgt length, batch size, tgt vocab size]\n",
        "\n",
        "      output_dim = output.shape[-1]\n",
        "      output = output[1:].view(-1, output_dim)  # output = [(tgt length - 1) * batch size, tgt vocab size]\n",
        "\n",
        "      tgt = tgt[1:].view(-1)  # tgt = [(tgt length - 1) * batch size]\n",
        "\n",
        "      loss = criterion(output, tgt)\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "  return epoch_loss / len(data_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhzBejuaLv2-"
      },
      "source": [
        "##Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "714vbT80Lyhj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e8daba4-ceeb-4420-fc26-2423a265a382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|â–ˆ         | 1/10 [07:39<1:08:57, 459.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss:   5.379 | Train PPL: 216.889\n",
            "\tValid Loss:   5.324 | Valid PPL: 205.179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|â–ˆâ–ˆ        | 2/10 [15:08<1:00:24, 453.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss:   4.242 | Train PPL:  69.568\n",
            "\tValid Loss:   4.732 | Valid PPL: 113.521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [22:38<52:42, 451.75s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss:   3.481 | Train PPL:  32.497\n",
            "\tValid Loss:   4.470 | Valid PPL:  87.328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [30:10<45:10, 451.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss:   2.915 | Train PPL:  18.456\n",
            "\tValid Loss:   4.278 | Valid PPL:  72.082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [37:43<37:42, 452.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss:   2.475 | Train PPL:  11.886\n",
            "\tValid Loss:   4.261 | Valid PPL:  70.911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [45:15<30:08, 452.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss:   2.129 | Train PPL:   8.408\n",
            "\tValid Loss:   4.176 | Valid PPL:  65.076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [52:48<22:37, 452.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss:   1.846 | Train PPL:   6.335\n",
            "\tValid Loss:   4.229 | Valid PPL:  68.638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [1:00:21<15:05, 452.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss:   1.619 | Train PPL:   5.050\n",
            "\tValid Loss:   4.197 | Valid PPL:  66.485\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [1:07:55<07:33, 453.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss:   1.432 | Train PPL:   4.188\n",
            "\tValid Loss:   4.219 | Valid PPL:  67.940\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [1:15:28<00:00, 452.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss:   1.284 | Train PPL:   3.610\n",
            "\tValid Loss:   4.273 | Valid PPL:  71.701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 10\n",
        "clip = 1.0\n",
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "best_valid_loss = float(\"inf\")\n",
        "\n",
        "train_loss_history = [0] * n_epochs\n",
        "valid_loss_history = [0] * n_epochs\n",
        "\n",
        "for epoch in tqdm.tqdm(range(n_epochs)):\n",
        "\n",
        "  train_loss = train_fn(\n",
        "    model,\n",
        "    train_data_loader,\n",
        "    optimizer,\n",
        "    criterion,\n",
        "    clip,\n",
        "    teacher_forcing_ratio,\n",
        "    device,\n",
        "  )\n",
        "\n",
        "  valid_loss = evaluate_fn(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    criterion,\n",
        "    device,\n",
        "  )\n",
        "\n",
        "  train_loss_history[epoch] = train_loss\n",
        "  valid_loss_history[epoch] = valid_loss\n",
        "\n",
        "  if valid_loss < best_valid_loss:\n",
        "    best_valid_loss = valid_loss\n",
        "    torch.save(model.state_dict(), \"gec-model_4_large.pt\") # Save model with weights as dict\n",
        "\n",
        "  print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n",
        "  print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_arr = np.arange(len(train_loss_history)) + 1\n",
        "fig = plt.figure(figsize=(12, 4))\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "ax.plot(x_arr, train_loss_history, \"-o\", label=\"Train loss\")\n",
        "ax.plot(x_arr, valid_loss_history, \"--<\", label=\"Valid loss\")\n",
        "ax.set_xlabel(\"Epoch\")\n",
        "ax.set_ylabel(\"Loss\")\n",
        "ax.legend(fontsize=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "XjXYQXjZ0953",
        "outputId": "8197b0ac-a3c7-4f32-9e5d-5bf0d60e3136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7c1d31de6e00>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQf86uUDMPY8"
      },
      "source": [
        "#Evaluation\n",
        "\n",
        "Loss here is derived from Cross Entropy (consider 'criterion' from previous cell). Perplexity is a metric that indicates how much \"surprised\" a model is when \"seeing\" new data. Perplexity is computed as the exponentiation of the loss produced by the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6cFrFuVMQiZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fe04f77-4a4b-4d73-fc98-5b975d98c330"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Test Loss: 5.206 | Test PPL: 182.371 |\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if torch.cuda.is_available():\n",
        "  model.load_state_dict(torch.load(\"gec-model_4_large.pt\"))\n",
        "else:\n",
        "  model.load_state_dict(torch.load(\"gec-model_4_large.pt\", map_location=torch.device(\"cpu\")))\n",
        "\n",
        "test_loss = evaluate_fn(model, test_data_loader, criterion, device)\n",
        "\n",
        "print(f\"| Test Loss: {test_loss:.3f} | Test PPL: {np.exp(test_loss):7.3f} |\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKO71UBjOl21"
      },
      "source": [
        "Function for making inferences with the model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iefvmXMXM-eN"
      },
      "outputs": [],
      "source": [
        "def correct_sentence(\n",
        "  sentence,\n",
        "  model,\n",
        "  en_vocab,\n",
        "  lower,\n",
        "  reverse,\n",
        "  sos_token,\n",
        "  eos_token,\n",
        "  device,\n",
        "  max_output_length=25,\n",
        "):\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    if isinstance(sentence, str):\n",
        "\n",
        "      if reverse:\n",
        "        tokens = sentence.split()[::-1]\n",
        "      else:\n",
        "        tokens = sentence.split()\n",
        "\n",
        "    else:\n",
        "\n",
        "      if reverse:\n",
        "        tokens = [token for token in sentence][::-1]\n",
        "      else:\n",
        "        tokens = [token for token in sentence]\n",
        "\n",
        "    if lower:\n",
        "\n",
        "      tokens = [token.lower() for token in tokens]\n",
        "      tokens = [sos_token] + tokens + [eos_token]\n",
        "      ids = en_vocab.lookup_indices(tokens)\n",
        "      tensor = torch.LongTensor(ids).unsqueeze(-1).to(device)\n",
        "      hidden, cell = model.encoder(tensor)\n",
        "      inputs = en_vocab.lookup_indices([sos_token])\n",
        "\n",
        "      for _ in range(max_output_length):\n",
        "\n",
        "        inputs_tensor = torch.LongTensor([inputs[-1]]).to(device)\n",
        "        output, hidden, cell = model.decoder(inputs_tensor, hidden, cell)\n",
        "        predicted_token = output.argmax(-1).item()\n",
        "        inputs.append(predicted_token)\n",
        "\n",
        "        if predicted_token == en_vocab[eos_token]:\n",
        "\n",
        "            break\n",
        "\n",
        "        tokens = en_vocab.lookup_tokens(inputs)\n",
        "\n",
        "  return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZV2N97BM-TQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4d525f2-f4b9-49c5-9c11-6a0b349986f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('All professional boxers are at risk from being killed in his next fight .',\n",
              " 'All professional boxers are at risk from being killed in their next fight .')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "sentence = test_data[2][\"src\"]\n",
        "expected_correction = test_data[2][\"tgt\"]\n",
        "\n",
        "sentence, expected_correction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kq3imPG9NUJq"
      },
      "outputs": [],
      "source": [
        "correction = correct_sentence(\n",
        "  sentence,\n",
        "  model,\n",
        "  en_vocab,\n",
        "  lower,\n",
        "  reverse,\n",
        "  sos_token,\n",
        "  eos_token,\n",
        "  device\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6TPAh8ZOSZx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5e6bdf0-72e4-4f7e-dfcb-b2a7d7e5d0f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos>',\n",
              " 'all',\n",
              " 'our',\n",
              " 'movies',\n",
              " 'are',\n",
              " 'at',\n",
              " '6',\n",
              " ',',\n",
              " ',',\n",
              " 'she',\n",
              " 'works',\n",
              " 'at',\n",
              " 'a',\n",
              " 'week',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "correction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkkwKTbsOnO3"
      },
      "source": [
        "##Inference\n",
        "\n",
        "The trained model is fed with the test data. The predictions with source and target sentences are stored at `test/model_name/`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids = []\n",
        "sentences = []\n",
        "references = []\n",
        "targets = []\n",
        "\n",
        "model_name = \"model_4\"\n",
        "\n",
        "os.makedirs(f\"test/{model_name}\", exist_ok=True)\n",
        "\n",
        "for i in range(len(test_data)):\n",
        "  sentence = test_data[i][\"src\"]\n",
        "  expected_correction = test_data[i][\"tgt\"]\n",
        "  correction = correct_sentence(\n",
        "    sentence,\n",
        "    model,\n",
        "    en_vocab,\n",
        "    lower,\n",
        "    reverse,\n",
        "    sos_token,\n",
        "    eos_token,\n",
        "    device\n",
        "  )\n",
        "\n",
        "  correction = \" \".join([token for token in correction][1:])\n",
        "\n",
        "  ids.append(i)\n",
        "  sentences.append(sentence)\n",
        "  references.append(expected_correction)\n",
        "  targets.append(correction)\n",
        "\n",
        "  with open(f\"test/{model_name}/sources.txt\", \"a\") as file:\n",
        "    file.write(sentence + \"\\n\")\n",
        "\n",
        "  with open(f\"test/{model_name}/references.txt\", \"a\") as file:\n",
        "    file.write(expected_correction + \"\\n\")\n",
        "\n",
        "  with open(f\"test/{model_name}/targets.txt\", \"a\") as file:\n",
        "    file.write(correction + \"\\n\")\n"
      ],
      "metadata": {
        "id": "h3tbPNmH4rUs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}